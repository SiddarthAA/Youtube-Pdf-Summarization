{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hugging Face Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Models**\n",
    "###### **1. facebook/bart-large-cnn (Short Summary)**\n",
    "###### **2. sshleifer/distilbart-cnn-12-6 (long Summary)**\n",
    "###### **3. bart-large-cnn-samsum (Alt Long Summary)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\siddu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, BertTokenizer, BertModel\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function To Return Content Chunks From Text And PDF File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "with open(\"Extract_Content.txt\",'r') as fh:\n",
    "    x = fh.read()\n",
    "    words = x.split(\" \")\n",
    "    print(len(words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1667, a Danish scientist finally concluded that certain mysterious stones prized for their supposed medicinal powers, hadnt fallen from the sky during lunar eclipses and werent serpent tongues. In fact, they were fossilized teeth many belonging to a prehistoric species that would come to be called megalodon, the biggest shark to ever live. So what was it like when megalodon ruled the seas? And what brought this formidable predator to extinction? Because their skeletons were cartilaginous, what remains of megalodons are mostly scattered clues, like some isolated vertebrae and lots of their enamel-protected teeth. Like many sharks, megalodons could shed and replace thousands of teeth over the course of their lives. Interestingly, some fossil sites harbor especially high numbers of small megalodon teeth. Experts believe these were nurseries that supported countless generations of budding megalodons. They grew up in sheltered  and food-packed shallow waters before becoming unrivaled adult marine hunters. Looking at the similarities  with great white shark teeth, scientists estimate that megalodons might have stretched up to 20 meters three times longer than great whites. And during their reign, which began around 20 million years ago, megalodons lived just about everywhere, with individuals also potentially undertaking transoceanic migrations.\n",
      "\n",
      "200\n",
      "The world was warmer and the ocean was brimming with life. Otters and dugongs thrived  in newly formed kelp forests, and baleen whales were at their most diverse. Megalodons had no shortage of high-energy, edible options. And it seems they were ambitious eaters. Generally, as carnivores consume protein-rich meat, certain nitrogen isotopes accumulate in their tissues including the enamel of their teeth. Analyzing megalodon teeth, scientists confirmed they were apex predators that not only ate large prey species but also other predators, perhaps even each other. In addition to megalodons teeth, researchers have access to one exceptionally well-preserved spinal column that comprises 141 vertebrae of a 46-year-old megalodon. A 3D model of the megalodons body suggests that its stomach could reach volumes of almost 10,000 liters big enough to fit an entire orca. Reconstructing their jaws, researchers think megalodons could eat a now-extinct 7-meter sperm whale in as few as four bites. And the fossilized bones of ancient cetaceans do indeed show evidence of megalodon bite marks  including some that healed over, confirming that megalodons pursued live prey. But if megalodons were so powerful, why did they go extinct? It seems there were a few contributing factors.\n",
      "\n",
      "197\n",
      "By the time they disappeared around 3.5 million years ago, the global climate had cooled, causing more glaciers to form and the sea level to drop. This dried up many coastal habitats, meaning some of the worlds most resource-rich marine sites were lost. About a third of all marine megafauna eventually went extinct, so fewer prey species were available. And megalodons already faced high energetic demands because of their size and the mechanism they likely used to regulate their body temperature, which allowed them  to navigate cold waters and attack prey with bursts of speed. Environmental changes may have made megalodons vulnerable and increasingly put them in competition with other predators, including the great white shark, a relative newcomer. Because megalodons were highly mobile predators, their extinction had global consequences. The end of their long-distance travels probably disrupted nutrient transport between different ecosystems. And many animals were suddenly released from the immense predatory pressure of their bite. Interestingly, some marine mammals dramatically increased in size afterwards, which was perhaps partially afforded because they were no longer dealing with such a mega-existential threat.\n",
      "\n",
      "182\n",
      "Knowing that the decline of apex predators can destabilize entire ecosystems, conservationists are working to prevent todays sharks from facing a similar fate this time, because of humans. And meanwhile, the megalodon remains a colossal testament to ecological interdependence and millions of years of bones well-bitten and waters well-wandered.\n",
      "\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "def main_chunk():\n",
    "    max_chunk_length=None\n",
    "\n",
    "    with open(\"Extract_Content.txt\",\"r\",encoding=\"utf-8\",errors=\"ignore\") as fh: \n",
    "        content = fh.read()\n",
    "        wrds = len(content.split(\" \"))\n",
    "        if wrds <= 1000:\n",
    "            max_chunk_length = 200\n",
    "        elif wrds <= 4000: \n",
    "            max_chunk_length = 500\n",
    "        else : \n",
    "            max_chunk_length = 1000\n",
    "\n",
    "\n",
    "    sentences = sent_tokenize(content)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())\n",
    "        if current_length + sentence_length <= max_chunk_length:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        else:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_length = sentence_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "for i in main_chunk():\n",
    "    print(f\"{i}\\n\")\n",
    "    print(len(i.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline Function To Summarize Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min(chunk_length):\n",
    "    if chunk_length <= 100:\n",
    "        max_length = max(50, int(chunk_length * 0.8)) \n",
    "    elif chunk_length <= 500:\n",
    "        max_length = max(100, int(chunk_length * 0.6)) \n",
    "    else:\n",
    "        max_length = max(200, int(chunk_length * 0.5)) \n",
    "    min_length = int(max_length * 0.5)\n",
    "    \n",
    "    return max_length, min_length\n",
    "\n",
    "#Model : bart-large-cnn\n",
    "#Short Summary Based On Given Text Chunks\n",
    "\n",
    "def short_summary(chunks, batch_size=8):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    batched_chunks = [chunks[i:i+batch_size] for i in range(0, len(chunks), batch_size)]\n",
    "    summaries = []\n",
    "    for batch in batched_chunks:\n",
    "        text = \"\\n\".join(batch)\n",
    "        summary = summarizer(text, max_length=300, min_length=100, do_sample=True, top_k=50, top_p=0.95)\n",
    "        summaries.extend([s['summary_text'] for s in summary])\n",
    "    return (\" \".join(summaries))\n",
    "\n",
    "#Model : distilbart-cnn-12-6\n",
    "#Long Summary Based On Given Text Chunks\n",
    "def long_summary(chunks):\n",
    "    summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk_length = len(chunk.split(\" \"))\n",
    "        max_len, min_len = max_min(chunk_length=chunk_length)\n",
    "        summary = summarizer(chunk, max_length=max_len, min_length=min_len, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    \n",
    "    return (\" \".join(summaries))\n",
    "\n",
    "#Model : bart-large-cnn-samsum\n",
    "#Long Summary Alt \n",
    "def long_alt_summary(chunks):\n",
    "    summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer(chunk, max_length=150, min_length=30, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    return (\" \".join(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_short_summary(chunks):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk_length = len(chunk.split(\" \"))\n",
    "        max_len, min_len = max_min(chunk_length=chunk_length)\n",
    "        summary = summarizer(chunk, max_length=max_len, min_length=min_len, do_sample=True, top_k=50, top_p=0.95)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    \n",
    "    return (\"\\n\".join(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = main_chunk()\n",
    "summary = new_short_summary(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fossilized teeth belong to a prehistoric species that would come to be called megalodon, the biggest shark to ever live. They grew up in sheltered  and food-packed shallow waters before becoming unrivaled adult marine hunters. Like many sharks, megalodons could shed and replace thousands of teeth over the course of their lives.\n",
      "\n",
      "Megalodons were apex predators that not only ate large prey species but also other predators. Researchers have access to one exceptionally well-preserved spinal column that comprises 141 vertebrae of a 46-year-old megalodon. 3D model of the megalodons body suggests that its stomach could reach volumes of almost 10,000 liters big enough to fit an entire orca.\n",
      "\n",
      "By the time they disappeared around 3.5 million years ago, the global climate had cooled, causing more glaciers to form and the sea level to drop. This dried up many coastal habitats, meaning some of the worlds most resource-rich marine sites were lost. About a third of all marine megafauna went extinct, so fewer prey species were available.\n",
      "\n",
      "Conservationists are working to prevent todays sharks from facing a similar fate this time, because of humans. And meanwhile, the megalodon remains a colossal testament to ecological interdependence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in summary.split(\"\\n\"):\n",
    "    print(f\"{i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
